{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition Using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Dependencies :\n",
    "\n",
    "* Install NLTK Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nltk library\n",
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "\n",
    "# Download the required resources which are used by NLTK's functions and algorithms\n",
    "nltk.download('punkt') # Download the Punkt tokenizer models for tokenization\n",
    "nltk.download('averaged_perceptron_tagger') # Download the averaged perceptron tagger models for part-of-speech tagging\n",
    "nltk.download('maxent_ne_chunker') # Download the maximum entropy chunker models for named entity chunking\n",
    "nltk.download('words') # Download lexical resources including a list of English words\n",
    "nltk.download('stopwords') # Download a list of common stopwords in the English language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the named entities from text using NLTK\n",
    "    \n",
    "Below are few examples for getting NER using NLTK\n",
    "\n",
    "* The Ashes series between England and Australia is a historic cricket rivalry.\n",
    "* Sachin Tendulkar is widely regarded as the greatest Indian batsman of all time.\n",
    "* The Chennai Super Kings have a loyal fan base known as the 'Yellow Army'.\n",
    "* Virat kohli is one of the best cricketer india has found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sentence\n",
    "sentence = \"The Chennai Super Kings have a most loyal fan base known as the 'Yellow Army'.\"\n",
    "\n",
    "# Step 1: Tokenize the sentence into words\n",
    "words = nltk.word_tokenize(sentence)\n",
    "\n",
    "# Step 2: Tag the words with their part-of-speech\n",
    "tags = nltk.pos_tag(words)\n",
    "\n",
    "# Step 3: Named Entity Recognition using NLTK's ne_chunk\n",
    "chunks = nltk.ne_chunk(tags)\n",
    "\n",
    "# Print the chunks\n",
    "print(f\"Named Entities:\\n\")\n",
    "print(chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the result in tree format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize named entities in tree format\n",
    "\n",
    "tree = Tree.fromstring(str(chunks))\n",
    "tree.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
